{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDENTIFYING CITIES TO INVEST IN RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}  \n",
    "df_city_vals = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_city_data(city_state):\n",
    "    city_values = pd.DataFrame()\n",
    "    cols = ['city','population_2000', 'population_2017', 'pop_growth_%', 'median_income_2000', 'median_income_2017', 'income_growth_%',\n",
    "            'median_house_2000', 'median_house_2017', 'median_house_growth_%', \n",
    "            'crime_index_2005', 'crime_index_2018', 'crime_increase_%', 'poverty_rate_%']\n",
    "\n",
    "    city_link = get_city_address(city_state)    \n",
    "    text = requests.get(city_link)\n",
    "    soup = BeautifulSoup(text.content, 'html.parser')\n",
    "    \n",
    "    # get populataion section\n",
    "    section_population = soup.find('section', {'id':'city-population'})\n",
    "    # get median income and house text\n",
    "    section_med_inc = soup.find('section', {'id':'median-income'})\n",
    "    # get crime section\n",
    "    section_crime_index = soup.find('section', {'id':'crime'})\n",
    "    # get povery level\n",
    "    section_poverty_level = soup.find('section', {'id':'poverty-level'})\n",
    "    \n",
    "    \n",
    "    tag_txt_house = 'Estimated median house or condo value in 2017:'\n",
    "    tag_txt_income = 'Estimated median household income in 2017:'\n",
    "    tag_txt_population = 'Population in 2017:'\n",
    "    tag_txt_poverty = 'Percentage of residents living in poverty in 2017:'\n",
    "        \n",
    "    tag = section_med_inc.find('b',text=tag_txt_house)\n",
    " \n",
    "    city_values == {}\n",
    "    all_fields = []\n",
    "    # get population data \n",
    "    population_fields = get_population(tag_txt_population, section_population)\n",
    "    # find and update the income values\n",
    "    income_fields = get_city_values(tag_txt_income, section_med_inc)\n",
    "    # find and update the median house values\n",
    "    house_fields = get_city_values(tag_txt_house, section_med_inc)\n",
    "    # find crimes index data\n",
    "    crime_index_fields = get_crime_index(section_crime_index)\n",
    "    # find crimes index data\n",
    "    poverty_level_field = get_poverty_level(tag_txt_poverty,section_poverty_level)    \n",
    "\n",
    "    all_fields.append(city_state)\n",
    "    all_fields.extend(population_fields)\n",
    "    all_fields.extend(income_fields)\n",
    "    all_fields.extend(house_fields)\n",
    "    all_fields.extend(crime_index_fields)\n",
    "    all_fields.extend(poverty_level_field)\n",
    "         \n",
    "    global df_city_vals\n",
    "    df_city_vals = df_city_vals.append(pd.DataFrame([all_fields], \n",
    "                                                    columns=cols),ignore_index = True)   \n",
    "    \n",
    "def get_city_values(srch_txt, section):\n",
    "    tag = section.find('b',text=srch_txt)   \n",
    "    latest_element = tag.next_sibling\n",
    "    compare_element = tag.findNext('b').next_sibling\n",
    "    compare_col = convert_to_num(compare_element)\n",
    "    latest_col = convert_to_num(latest_element)    \n",
    "    pct_diff =  get_pct(latest_col, compare_col)\n",
    "    \n",
    "    return [int(compare_col), int(latest_col), float(pct_diff)]\n",
    "\n",
    "def get_population(srch_txt, section):\n",
    "#     print(section)\n",
    "    tag = section.find('b',text=srch_txt) \n",
    "    latest_col_txt = tag.next_sibling\n",
    "    latest_col_txt = latest_col_txt.split('(')[0];\n",
    "    latest_col = convert_to_num(latest_col_txt)    \n",
    "\n",
    "    pct_diff = tag.findNext('b').next_sibling.split('%')[0]\n",
    "    pct_diff = float(pct_diff)\n",
    "    \n",
    "    # poulation of latest year and % diff is provided, need to calculate what was the population\n",
    "    compare_popln = latest_col/(1 + pct_diff/100);\n",
    "\n",
    "#     compare_col = convert_to_num(compare_element)\n",
    "#     latest_col = convert_to_num(latest_element)    \n",
    "#     pct_diff =  get_pct(latest_col, compare_col)\n",
    "    \n",
    "    return [int(compare_popln), int(latest_col), float(pct_diff)]\n",
    "\n",
    "def get_crime_index(section_crime):\n",
    "    # if no crime data found for the city\n",
    "    if section_crime == None:\n",
    "        return [None, None, None]\n",
    "    cr = section_crime.find_all('tr', {\"class\": \"nosort\"})[0]\n",
    "    crimes = []\n",
    "    for idx, val in enumerate(cr.find_all('td')):\n",
    "        if idx != 0:\n",
    "            crime = val.text.strip()\n",
    "            crimes.append(float(crime))\n",
    "    cr_pct_dff = get_pct(crimes[0], crimes[1])            \n",
    "    return [crimes[0], crimes[-1], cr_pct_dff] \n",
    "\n",
    "def get_poverty_level(srch_txt, section_poverty):\n",
    "    if section_poverty == None:\n",
    "        return [None, None, None]\n",
    "    tag = section_poverty.find('b',text=srch_txt)\n",
    "    poverty_level_txt = tag.next_sibling\n",
    "    poverty_level_txt = poverty_level_txt.split('%')[0];\n",
    "    poverty_level = float(poverty_level_txt)     \n",
    "    return [poverty_level] \n",
    "\n",
    "def convert_to_num(text):\n",
    "    tex = text.replace(',', '')\n",
    "    return int(re.search('[0-9]+',tex).group(0))\n",
    "\n",
    "def get_pct(num1, num2):\n",
    "    return round((num1/num2  - 1) * 100, 2)\n",
    "\n",
    "def get_city_address(City_link):\n",
    "    city_data_address = 'http://www.city-data.com'\n",
    "    return city_data_address + '/city/' + City_link + '.html'\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Flint-Michigan\n",
       "1        Detroit-Michigan\n",
       "2         Youngstown-Ohio\n",
       "3            Gary-Indiana\n",
       "4    Reading-Pennsylvania\n",
       "Name: Cities_ready, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_data = 'data/large_market_database.csv'\n",
    "df = pd.read_csv(cities_data)\n",
    "df.head\n",
    "cities = []\n",
    "for city in df['Location']:\n",
    "    #   concatenate city and state with '-', replace empty space with '-' and ' with -\n",
    "    #   O'Fallon-Missouri to O-Fallon-Missouri\n",
    "    cy = city.replace(' , ', '-').replace(' ','-').replace(\"'\", '-').replace(',-','-').replace('--', '-')\n",
    "    cities.append(cy)\n",
    "df['Cities_ready'] = cities  \n",
    "# drop cities containing \"balance\" \n",
    "# like\"Augusta-Richmond-County-consolidated-government-(balance)-Georgia\"\n",
    "df_cy = df[~df.Cities_ready.str.contains(\"balance\")]\n",
    "citis_ser = df_cy.iloc[:]['Cities_ready']\n",
    "citis_ser.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 547: Flint-Michigan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #for testing\n",
    "# data = np.array(['Round-Rock-Texas', \"Flint-Michigan\"])  \n",
    "# citis_ser = pd.Series(data)\n",
    "\n",
    "# parse_city_data('Miami-Gardens-Florida')        \n",
    "for idx, city in enumerate(citis_ser):\n",
    "    print(str(idx) + ' of ' + str(citis_ser.count()) + ': ' + city)\n",
    "    try:\n",
    "        parse_city_data(city)\n",
    "        # protecting throtling from city-data\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print('Data not found for: ' + city)\n",
    "        print(str(e))\n",
    "        pass\n",
    "df_file = 'data/cities_market_data.csv'\n",
    "df_city_vals.to_csv(df_file, index=False)\n",
    "df_city_vals.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = 'data/cities_market_data.csv'\n",
    "df_city_vals.to_csv(df_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
